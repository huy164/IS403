{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP1VUy/49/jMs4yOH2Wf/qr"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Yjkxu-iwU32W","executionInfo":{"status":"ok","timestamp":1685685057574,"user_tz":-420,"elapsed":94748,"user":{"displayName":"Tin Lam Xuong","userId":"06912241339234627479"}},"outputId":"0b15a747-5028-4739-c756-2bf46a80ec71"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","117/117 [==============================] - 6s 26ms/step - loss: 0.0013 - val_loss: 1.6611e-04\n","Epoch 2/50\n","117/117 [==============================] - 3s 22ms/step - loss: 7.6999e-05 - val_loss: 3.4409e-04\n","Epoch 3/50\n","117/117 [==============================] - 4s 33ms/step - loss: 7.4072e-05 - val_loss: 3.2646e-04\n","Epoch 4/50\n","117/117 [==============================] - 2s 20ms/step - loss: 7.5537e-05 - val_loss: 1.7422e-04\n","Epoch 5/50\n","117/117 [==============================] - 2s 21ms/step - loss: 7.5644e-05 - val_loss: 1.3086e-04\n","Epoch 6/50\n","117/117 [==============================] - 2s 20ms/step - loss: 6.7125e-05 - val_loss: 1.6235e-04\n","Epoch 7/50\n","117/117 [==============================] - 2s 16ms/step - loss: 7.6265e-05 - val_loss: 1.2580e-04\n","Epoch 8/50\n","117/117 [==============================] - 1s 13ms/step - loss: 8.4191e-05 - val_loss: 1.4253e-04\n","Epoch 9/50\n","117/117 [==============================] - 2s 17ms/step - loss: 6.5118e-05 - val_loss: 1.4581e-04\n","Epoch 10/50\n","117/117 [==============================] - 2s 13ms/step - loss: 6.5709e-05 - val_loss: 1.3787e-04\n","Epoch 11/50\n","117/117 [==============================] - 1s 12ms/step - loss: 6.8138e-05 - val_loss: 1.2461e-04\n","Epoch 12/50\n","117/117 [==============================] - 1s 11ms/step - loss: 7.4402e-05 - val_loss: 1.7320e-04\n","Epoch 13/50\n","117/117 [==============================] - 1s 11ms/step - loss: 5.7306e-05 - val_loss: 1.4688e-04\n","Epoch 14/50\n","117/117 [==============================] - 1s 11ms/step - loss: 6.7327e-05 - val_loss: 1.2114e-04\n","Epoch 15/50\n","117/117 [==============================] - 1s 13ms/step - loss: 6.1520e-05 - val_loss: 1.1127e-04\n","Epoch 16/50\n","117/117 [==============================] - 1s 12ms/step - loss: 6.5144e-05 - val_loss: 2.2251e-04\n","Epoch 17/50\n","117/117 [==============================] - 2s 14ms/step - loss: 5.4659e-05 - val_loss: 2.0259e-04\n","Epoch 18/50\n","117/117 [==============================] - 2s 19ms/step - loss: 6.2169e-05 - val_loss: 1.0701e-04\n","Epoch 19/50\n","117/117 [==============================] - 1s 12ms/step - loss: 5.9683e-05 - val_loss: 1.3319e-04\n","Epoch 20/50\n","117/117 [==============================] - 1s 11ms/step - loss: 5.3565e-05 - val_loss: 2.5775e-04\n","Epoch 21/50\n","117/117 [==============================] - 1s 11ms/step - loss: 6.2238e-05 - val_loss: 1.1625e-04\n","Epoch 22/50\n","117/117 [==============================] - 2s 13ms/step - loss: 5.7422e-05 - val_loss: 2.2092e-04\n","Epoch 23/50\n","117/117 [==============================] - 1s 12ms/step - loss: 5.8627e-05 - val_loss: 4.4981e-04\n","Epoch 24/50\n","117/117 [==============================] - 1s 12ms/step - loss: 6.1368e-05 - val_loss: 1.4138e-04\n","Epoch 25/50\n","117/117 [==============================] - 1s 11ms/step - loss: 5.9960e-05 - val_loss: 1.2386e-04\n","Epoch 26/50\n","117/117 [==============================] - 2s 17ms/step - loss: 6.2350e-05 - val_loss: 1.4235e-04\n","Epoch 27/50\n","117/117 [==============================] - 2s 15ms/step - loss: 5.5287e-05 - val_loss: 1.1717e-04\n","Epoch 28/50\n","117/117 [==============================] - 1s 11ms/step - loss: 5.5362e-05 - val_loss: 1.5785e-04\n","Epoch 29/50\n","117/117 [==============================] - 1s 10ms/step - loss: 7.0254e-05 - val_loss: 1.9589e-04\n","Epoch 30/50\n","117/117 [==============================] - 1s 11ms/step - loss: 5.4472e-05 - val_loss: 1.0598e-04\n","Epoch 31/50\n","117/117 [==============================] - 1s 10ms/step - loss: 5.4890e-05 - val_loss: 1.2508e-04\n","Epoch 32/50\n","117/117 [==============================] - 1s 12ms/step - loss: 5.6964e-05 - val_loss: 1.5967e-04\n","Epoch 33/50\n","117/117 [==============================] - 1s 11ms/step - loss: 5.9855e-05 - val_loss: 2.0453e-04\n","Epoch 34/50\n","117/117 [==============================] - 1s 11ms/step - loss: 5.5350e-05 - val_loss: 1.3170e-04\n","Epoch 35/50\n","117/117 [==============================] - 2s 15ms/step - loss: 5.3360e-05 - val_loss: 6.6370e-04\n","Epoch 36/50\n","117/117 [==============================] - 2s 17ms/step - loss: 6.7613e-05 - val_loss: 2.9748e-04\n","Epoch 37/50\n","117/117 [==============================] - 1s 12ms/step - loss: 5.5953e-05 - val_loss: 3.7232e-04\n","Epoch 38/50\n","117/117 [==============================] - 1s 11ms/step - loss: 5.4765e-05 - val_loss: 1.0775e-04\n","Epoch 39/50\n","117/117 [==============================] - 1s 12ms/step - loss: 5.3629e-05 - val_loss: 1.0833e-04\n","Epoch 40/50\n","117/117 [==============================] - 1s 13ms/step - loss: 5.1962e-05 - val_loss: 1.1195e-04\n","Epoch 41/50\n","117/117 [==============================] - 1s 11ms/step - loss: 5.7839e-05 - val_loss: 1.9401e-04\n","Epoch 42/50\n","117/117 [==============================] - 1s 11ms/step - loss: 5.0257e-05 - val_loss: 1.4498e-04\n","Epoch 43/50\n","117/117 [==============================] - 1s 13ms/step - loss: 5.3008e-05 - val_loss: 1.2597e-04\n","Epoch 44/50\n","117/117 [==============================] - 2s 17ms/step - loss: 5.6682e-05 - val_loss: 1.2112e-04\n","Epoch 45/50\n","117/117 [==============================] - 2s 16ms/step - loss: 5.4205e-05 - val_loss: 2.1395e-04\n","Epoch 46/50\n","117/117 [==============================] - 1s 10ms/step - loss: 5.3762e-05 - val_loss: 1.3001e-04\n","Epoch 47/50\n","117/117 [==============================] - 1s 9ms/step - loss: 5.6688e-05 - val_loss: 5.4192e-04\n","Epoch 48/50\n","117/117 [==============================] - 1s 9ms/step - loss: 5.3650e-05 - val_loss: 2.9296e-04\n","Epoch 49/50\n","117/117 [==============================] - 1s 10ms/step - loss: 5.2254e-05 - val_loss: 1.2272e-04\n","Epoch 50/50\n","117/117 [==============================] - 1s 10ms/step - loss: 6.0130e-05 - val_loss: 1.4948e-04\n","78/78 [==============================] - 0s 4ms/step - loss: 0.0028\n","Loss:  0.0028167162090539932\n","234/234 [==============================] - 1s 4ms/step\n","78/78 [==============================] - 0s 4ms/step\n","78/78 [==============================] - 1s 6ms/step\n"]}],"source":["import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","from sklearn.preprocessing import MinMaxScaler\n","\n","# Load data\n","data = pd.read_csv('https://raw.githubusercontent.com/huy164/datasets/master/walmart_stock_price.csv')\n","dates = data['Date'].values.astype(np.datetime64)\n","prices = data['Close'].values.astype('float32')\n","\n","# Split data into train, validation, and test sets\n","train_size = int(0.6 * len(prices))\n","val_size = int(0.2 * len(prices))\n","test_size = len(prices) - train_size - val_size\n","train_data = prices[:train_size].reshape(-1, 1)\n","val_data = prices[train_size:train_size+val_size].reshape(-1, 1)\n","test_data = prices[train_size+val_size:].reshape(-1, 1)\n","\n","# Normalize data\n","scaler = MinMaxScaler()\n","train_data = scaler.fit_transform(train_data)\n","val_data = scaler.transform(val_data)\n","test_data = scaler.transform(test_data)\n","\n","# Define sequence length and number of features\n","seq_length = 30\n","num_features = 1\n","\n","# Create sequences\n","def create_sequences(data, seq_length):\n","    X = []\n","    y = []\n","    for i in range(len(data)-seq_length-1):\n","        X.append(data[i:i+seq_length])\n","        y.append(data[i+seq_length])\n","    return np.array(X), np.array(y)\n","\n","X_train, y_train = create_sequences(train_data, seq_length)\n","X_val, y_val = create_sequences(val_data, seq_length)\n","X_test, y_test = create_sequences(test_data, seq_length)\n","\n","# Define model architecture\n","model = tf.keras.Sequential([\n","    tf.keras.layers.SimpleRNN(64, input_shape=(seq_length, num_features)),\n","    tf.keras.layers.Dense(1)\n","])\n","\n","# Compile model\n","model.compile(optimizer='adam', loss='mse')\n","\n","# Train model\n","model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=50, batch_size=64)\n","\n","# Evaluate model\n","loss = model.evaluate(X_test, y_test)\n","print('Loss: ', loss)\n","\n","train_predictions = scaler.inverse_transform(model.predict(X_train))\n","val_predictions = scaler.inverse_transform(model.predict(X_val))\n","test_predictions = scaler.inverse_transform(model.predict(X_test))"]}]}